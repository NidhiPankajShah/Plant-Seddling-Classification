import os
import numpy as np
import cv2
import matplotlib.pyplot as plt

from config import *


def create_mask_for_plant(image):
    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    sensitivity = 35
    lower_hsv = np.array([60 - sensitivity, 100, 50])
    upper_hsv = np.array([60 + sensitivity, 255, 255])

    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

    return mask


def segment_plant(image):
    mask = create_mask_for_plant(image)
    output = cv2.bitwise_and(image, image, mask=mask)
    return output


def sharpen_image(image):
    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)
    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)
    return image_sharp


if __name__ == '__main__':
    for index, label in enumerate(labels):
        folder_path = os.path.join('train', label)
        for file in os.listdir(folder_path):
            image_path = os.path.join(folder_path, file)
            image_bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)
            image_segmented = segment_plant(image_bgr)
            image_sharpen = sharpen_image(image_segmented)
            save_path = os.path.join('seg_train', label)
            if not os.path.isdir(save_path):
                os.mkdir(save_path)
            cv2.imwrite(os.path.join(save_path, file), image_sharpen)

    for file in os.listdir('test'):
        image_path = os.path.join('test', file)
        image_bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)
        image_segmented = segment_plant(image_bgr)
        image_sharpen = sharpen_image(image_segmented)
        cv2.imwrite(os.path.join('preprocess', file), image_sharpen)




from google.colab import drive
drive.mount('/content/drive')

import mxnet as mx
import os, sys, requests

def get_iterators(batch_size, data_shape=(3, 224, 224)):
    train = mx.io.ImageRecordIter(
        path_imgrec         = '/content/drive/My Drive/plant/train-lst.rec',
        data_name ='data',
        label_name          = 'softmax_label',
        batch_size          = batch_size,
        data_shape          = data_shape,
        shuffle             = True,
        rand_crop           = True,
        rand_mirror         = True)
    val = mx.io.ImageRecordIter(
        path_imgrec         = '/content/drive/My Drive/plant/test-lst.rec',
        data_name ='data',
        label_name          = 'softmax_label',
        batch_size          = batch_size,
        data_shape          = data_shape,
        rand_crop           = False,
        rand_mirror         = False)
    return (train, val)
    
    def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='flatten0'):
    """
    symbol: the pretrained network symbol
    arg_params: the argument parameters of the pretrained model
    num_classes: the number of classes for the fine-tune datasets
    layer_name: the layer name before the last fully-connected layer
    """
    all_layers = symbol.get_internals()
    net = all_layers[layer_name+'_output']
    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')
    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')
    new_args = dict({k:arg_params[k] for k in arg_params if 'fc1' not in k})
    return (net, new_args)
    
    
    sym, arg_params, aux_params = mx.model.load_checkpoint('/content/drive/My Drive/plant/resnet-50', 0)
    
    
    import logging
head = '%(asctime)-15s %(message)s'
logging.basicConfig(level=logging.DEBUG, format=head)

def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus):
    devs = [mx.gpu(i) for i in range(num_gpus)]
    mod = mx.mod.Module(symbol=symbol, context=mx.gpu())
    mod.fit(train, val,
        num_epoch=100,
        arg_params=arg_params,
        aux_params=aux_params,
        allow_missing=True,
        batch_end_callback = mx.callback.Speedometer(batch_size, 10),
        kvstore='device',
        optimizer='sgd',
        optimizer_params={'learning_rate':0.01},
        initializer=mx.init.Xavier(rnd_type='gaussian', factor_type="in", magnitude=2),
        eval_metric='acc')
    metric = mx.metric.Accuracy()
    mod.save_checkpoint('resnet_checkpoint', 1, False)
    return mod.score(val, metric)
    
    
    num_classes = 12
batch_per_gpu = 16
num_gpus = 1

(new_sym, new_args) = get_fine_tune_model(sym, arg_params, num_classes)

batch_size = batch_per_gpu * num_gpus
(train, val) = get_iterators(batch_size)
mod_score = fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus)
assert mod_score > 0.77, "Low training accuracy."
